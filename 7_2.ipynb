{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "import numpy as np\r\n",
    "from scipy.stats import norm\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from scipy import stats\r\n",
    "import statsmodels.stats.diagnostic as diag\r\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, confusion_matrix\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.tree import DecisionTreeClassifier\r\n",
    "from sklearn.tree import DecisionTreeRegressor\r\n",
    "from sklearn.ensemble import RandomForestClassifier\r\n",
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "from sklearn import tree\r\n",
    "from sklearn import metrics\r\n",
    "from sklearn import datasets\r\n",
    "from sklearn.model_selection import cross_val_predict\r\n",
    "from sklearn.model_selection import GridSearchCV\r\n",
    "import sklearn.preprocessing\r\n",
    "import random\r\n",
    "import graphviz\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.svm import SVR\r\n",
    "## import pyclustertend \r\n",
    "import matplotlib.cm as cm\r\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./train.csv', encoding = \"latin1\")\r\n",
    "file = open('cuantitativas.txt', 'r')\r\n",
    "quant= file.read().splitlines()\r\n",
    "file = open('cualitativas.txt', 'r')\r\n",
    "quali= file.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables de interes\r\n",
    "print('\\033[36m' + 'Kurtosis: %f' % data['SalePrice'].kurt())\r\n",
    "print('\\033[36m' + 'Asimetría: %f' % data['SalePrice'].skew())\r\n",
    "data['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat,p = stats.shapiro(data[[\"SalePrice\"]].dropna())\r\n",
    "print('Prueba de Kolmogorov-Smirnov:\\np=%f\\n'% p)\r\n",
    "ks_statistic, p_value = diag.lilliefors(data[[\"SalePrice\"]].dropna())\r\n",
    "print('Prueba de Lilliefors:\\nks=%f\\np=%f'%(ks_statistic,p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data['SalePrice'], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(0)\r\n",
    "minPrice = data['SalePrice'].min()\r\n",
    "maxPrice = data['SalePrice'].max()\r\n",
    "divs = (maxPrice - minPrice) / 3\r\n",
    "data['priceRange'] = data['LotArea']\r\n",
    "\r\n",
    "data['priceRange'][data['SalePrice'] < minPrice + divs] = 0.0 #Economico\r\n",
    "data['priceRange'][data['SalePrice'] >= minPrice + divs] = 1.0 #Precio medio\r\n",
    "data['priceRange'][data['SalePrice'] >= minPrice + divs * 2] = 2.0 #Caro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data['priceRange']\r\n",
    "X = data.drop(['priceRange'], axis=1)\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procesamiento de variables cuantitativas y cualitativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "from sklearn.pipeline import Pipeline\r\n",
    "from sklearn.compose import ColumnTransformer\r\n",
    "\r\n",
    "numeric_preprocessor = Pipeline(\r\n",
    "    steps=[(\"imputer\", SimpleImputer(strategy=\"median\")), (\"scaler\", StandardScaler())]\r\n",
    ")\r\n",
    "\r\n",
    "categorical_preprocessor = OneHotEncoder(handle_unknown=\"ignore\")\r\n",
    "\r\n",
    "preprocesador = ColumnTransformer([\r\n",
    "    ('one_hot_encoder',categorical_preprocessor,quali),\r\n",
    "    ('numerico', numeric_preprocessor,quant)\r\n",
    "],remainder=\"passthrough\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocesamiento + modelo en un paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\r\n",
    "from sklearn import set_config\r\n",
    "\r\n",
    "modelo = make_pipeline(preprocesador, SVC(kernel=\"linear\"))\r\n",
    "\r\n",
    "set_config(display='diagram')\r\n",
    "modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamiento de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=modelo.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pred = modelo.predict(X_test)\r\n",
    "print(target_pred)\r\n",
    "print (\"Accuracy:\",metrics.accuracy_score(y_test, target_pred))\r\n",
    "print (\"Precision:\", metrics.precision_score(y_test,target_pred,average='weighted') )\r\n",
    "print (\"Recall: \", metrics.recall_score(y_test,target_pred,average='weighted'))\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import  confusion_matrix\r\n",
    "confusion_matrix(target_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajuste de validacion cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, cross_val_predict\r\n",
    "cv = 8\r\n",
    "cv_results = cross_validate(modelo,data, Y, cv=cv)\r\n",
    "cv_results = pd.DataFrame(cv_results)\r\n",
    "print(\"accuracy: \"+str(cv_results['test_score'].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_pred = cross_val_predict(modelo, data, Y, cv = cv)\r\n",
    "confusion_matrix(Y, target_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la realización de la validación cruzada, se puede mejorar el sobreajuste que se debe al modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tuneo de parámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = make_pipeline(preprocesador, SVC(kernel=\"poly\"))\r\n",
    "_=modelo.fit(X_train,y_train)\r\n",
    "param_grid = {\r\n",
    "    'svc__C': (0.01, 0.1, 1, 5,16,32),\r\n",
    "    'svc__degree':(2,3,5,7)\r\n",
    "    }\r\n",
    "model_grid_search = GridSearchCV(modelo, param_grid=param_grid,\r\n",
    "                                 n_jobs=2, cv=5)\r\n",
    "model_grid_search.fit(X_train, y_train)\r\n",
    "accuracy = model_grid_search.score(X_test, y_test)\r\n",
    "print(\"Accuracy: \",accuracy)\r\n",
    "model_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = make_pipeline(preprocesador, SVC(kernel=\"rbf\"))\r\n",
    "_=modelo.fit(X_train,y_train)\r\n",
    "param_grid = {\r\n",
    "    'svc__C': (0.01, 0.1, 1, 5,16,32),\r\n",
    "    'svc__gamma':(0.0000000002,0.00002,0.01,0.1,20,200)\r\n",
    "    }\r\n",
    "model_grid_search = GridSearchCV(modelo, param_grid=param_grid,\r\n",
    "                                 n_jobs=2, cv=5)\r\n",
    "model_grid_search.fit(X_train, y_train)\r\n",
    "accuracy = model_grid_search.score(X_test, y_test)\r\n",
    "print(\"Accuracy: \",accuracy)\r\n",
    "model_grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(model_grid_search.cv_results_).sort_values(\r\n",
    "    \"mean_test_score\", ascending=False)\r\n",
    "cv_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "6cb11118430048aaffde37140829a96b2f2778371a079ecf7cef1d9eee249f62"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}